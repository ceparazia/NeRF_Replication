task: "nerf_replication"
gpus: [0] # set gpu device number
exp_name: "nerf"
scene: "lego"

train_dataset_module: src.datasets.nerf.blender
test_dataset_module: src.datasets.nerf.blender
network_module: src.models.nerf.network
renderer_module: src.models.nerf.renderer.volume_renderer
loss_module: src.train.trainers.nerf
evaluator_module: src.evaluators.nerf

task_arg:
  N_rays: 1024 # number of rays in each batch   默认值1024  这是训练时候一次取出的光线数。不影响测试时候的性能
  chunk_size: 4096 # number of rays processed in parallel
  # 这是网络内部的分块大小，我用不到
  # chunk_size: 256
  # chunk_size是net里面一次处理的光线数

  # rays_chunk_size: 16384 # ❗ 这是我自己加的。是渲染前手动对光线分块、传入net,避免embed的时候OOM
  rays_chunk_size: 65536
  # 这个大小对渲染质量没影响，但是会影响渲染速度


  # ❗下面的ERT和ESS相关参数是我自己加的
  use_ERT: True
  ERT_threshold: 6e-2   # 阈值取[0.05,0.07]区间内的值，可以在保证PSNR大于30的情况下做到最快
  # 如果取1e-1可以进一步加速，但是PSNR会下降为29点多。如果取1e-1以上，图像质量会明显下降
  ERT_chunk: 8   # 测试发现取8，16，32的加速效果比较好。大于32后，提速效果下降了


  use_ESS: True
  force_gen_occ_grid: False  # 强制重新生成occ_grid
  occ_filename: "occupancy_Q"
  occ_res: [128,128,128]  # Occupancy grid将有128^3个体素
  # occ_res: [256,256,256]
  voxel_sample: [3,3,3]   # 每个体素内采集[3,3,3]共27个点，判断这个体素是否被占据
  occ_threshold: 1e-4  # 一个体素中若有1个点的σ达到阈值，就认为这个体素是被占据的
  AABB_min: [-2.0, -2.0, -2.0]
  AABB_max: [2.0 ,  2.0,  2.0]
  voxel_chunk: True  # 分块处理体素来构建occupancy grid，避免OOM
  voxel_chunk_size: 65536





  
  white_bkgd: 1 # use white background

  N_samples: 64 # number of samples per ray in coarse network     默认值 64
  # 在开启ESS的情况下，减小N_samples可以提速，但是N_samples小于48就会导致PSNR低于30.
  # 若取N_samples=16，会出现部分三维结构残缺，PSNR在28.5左右
  # 若取N_samples=16，会出现明显的部分三维结构缺失，PSNR在24左右

  N_importance: 128 # number of samples per ray in fine network  默认值是128
  # 在开启ESS的情况下，减小N_importance可以提速
  # N_importance越小提速越明显，而且图像质量的下降是可接受的
  # N_importance取128时PSNR是30.01  fps=0.9769
  # N_importance取64时PSNR是29.95   fps=1.7929
  # N_importance取32时PSNR是29.72   fps=2.6540
  # N_importance取16时PSNR是29.08   fps=3.4382  如果要保住29的PSNR，这大概是极限了



  no_batching: True # True for synthetic datasets
  use_viewdirs: True # whether use full 5D input instead of 3D
  lindisp: False
  perturb: 1
  raw_noise_std: 0
  use_pe: True # whether use positional encoding
  test_skip: 1 # will load 1/N images from test/val sets, useful for large datasets
  precrop_iters: 500
  precrop_frac: 0.5

network:
  nerf:
    W: 256 # width of network
    D: 8 # depth of network
    V_D: 1 # appearance depth
    skips: [4]
  xyz_encoder: # encoder for location
    type: "frequency"
    input_dim: 3 # dimensions of input data
    freq: 10 # dimensions of encoding location
  dir_encoder: # encoder for direction
    type: "frequency"
    input_dim: 3 # dimensions of input data
    freq: 4 # dimensions of encoding direction

train_dataset:
  data_root: "data/nerf_synthetic"
  split: "train"
  input_ratio: 1. # whether to downsampling the image, you can set it to 0.5 to acclerate training
  cams: [0, -1, 1] # input cameras, you can use this variable to select training images
  #这个写法会被用作python切片，这里就是从0一直取到最后，也就是在训练时加载所有图像。
  H: 800
  W: 800

test_dataset:
  data_root: "data/nerf_synthetic"
  split: "test"
  input_ratio: 0.5   
  # input_ratio: 1.0  # 改成1.0可以提高渲染质量，但是会慢很多

  # cams: [0, -1, 100]  #在测试集里面，每100个抽取1个，而不是全部加载
  cams: [0, -1, 50]  # 每20个视角抽取1个.这样可以渲染出10张图片
  H: 800
  W: 800

train:
  single_view: False
  batch_size: 1
  lr: 5e-4 # learning rate
  weight_decay: 0.
  epoch: 600
  optim: 'adam'
  scheduler:
    type: "exponential"
    gamma: 0.1
    decay_epochs: 500 # original 1000
  num_workers: 4

test:
  batch_size: 1

eval:
  whole_img: True

ep_iter: 500 # number of iterations in each epoch
# save_ep: 40  # 每40次保存一次模型
save_ep: 20  # 改为每20次保存一次模型

eval_ep: 40 # 20000 iterations
# save_latest_ep: 10 # 5000 iterations
save_latest_ep: 1   # 改为每个周期都记录最新模型

# log_interval: 10
log_interval: 1   # 获取最详细的日志
